{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39770ddd",
   "metadata": {},
   "source": [
    "# Schema Silver\n",
    "\n",
    "Autor: Thiago Vilarinho Lemes\\\n",
    "Projeto: ETL no Databricks utilizando Catalog \\\n",
    "Data: 14/09/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b7af596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, sum, when\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b61a9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega as variáveis de ambiente do arquivo .env\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "catalog_name = os.getenv(\"NAME_CATALOG\")\n",
    "\n",
    "schema_bronze = os.getenv(\"NAME_SCHEMA_BRONZE\")\n",
    "table_bronze = os.getenv(\"NAME_TABLE_BRONZE\")\n",
    "\n",
    "schema_silver = os.getenv(\"NAME_SCHEMA_SILVER\")\n",
    "table_silver = os.getenv(\"NAME_TABLE_SILVER\")\n",
    "\n",
    "schema_gold = os.getenv(\"NAME_SCHEMA_GOLD\")\n",
    "table_gold = os.getenv(\"NAME_TABLE_GOLD\")\n",
    "\n",
    "schema_raw = os.getenv(\"NAME_SCHEMA_RAW\")\n",
    "bucket_raw = os.getenv(\"NAME_STORAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ad61d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a sessão Spark usando Databricks Connect\n",
    "spark = DatabricksSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e74522fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog e Schema selecionados: catalogo_netflix_movies.silver\n"
     ]
    }
   ],
   "source": [
    "# Seleciona o catalog e schema a serem utilizados\n",
    "try:\n",
    "    spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "    spark.sql(f\"USE SCHEMA {schema_silver}\")\n",
    "    print(f\"Catalog e Schema selecionados: {catalog_name}.{schema_silver}\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao selecionar Catalog ou Schema: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0bc702b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_name = catalog_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "10c8f79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leitura da tabela catalogo_netflix_movies.bronze.None realizada com sucesso.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175a7b17b67145b38f2b5f1af466b119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+--------------------+--------------------+--------------------+----------------+------------+------+--------+--------------------+--------------------+\n",
      "|show_id|   type|               title|            director|                cast|             country|      date_added|release_year|rating|duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+--------------------+--------------------+--------------------+----------------+------------+------+--------+--------------------+--------------------+\n",
      "|  s6566|  Movie|         Dark Crimes|  Alexandros Avranas|Jim Carrey, Marto...|United Kingdom, P...|October 15, 2019|        2016|     R|  93 min|   Dramas, Thrillers|A detective on a ...|\n",
      "|  s6567|  Movie|         Dark Places|Gilles Paquet-Bre...|Charlize Theron, ...|United States, Un...|   July 26, 2018|        2015|     R| 113 min|Dramas, Internati...|Years after survi...|\n",
      "|  s6568|  Movie|      Darna Mana Hai|        Prawal Raman|Aftab Shivdasani,...|               India|  August 1, 2019|        2003| TV-MA| 116 min|Horror Movies, In...|Stranded in a jun...|\n",
      "|  s6569|TV Show|Darr Sabko Lagta Hai|                NULL|        Bipasha Basu|               India|   March 1, 2018|        2015| TV-MA|1 Season|International TV ...|In this chilling ...|\n",
      "|  s6570|  Movie|               Darra|       Parveen Kumar|Gurpreet Ghuggi, ...|               India|October 15, 2017|        2016| TV-14| 121 min|Dramas, Internati...|After returning f...|\n",
      "+-------+-------+--------------------+--------------------+--------------------+--------------------+----------------+------------+------+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = spark.read.table(f\"{catalog_name}.{schema_bronze}.{table_bronze}\")\n",
    "    print(f\"Leitura da tabela {catalog_name}.{schema_bronze}.{table_bronze} realizada com sucesso.\")\n",
    "    df.show(5)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao ler a tabela: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6725adbc",
   "metadata": {},
   "source": [
    "Analise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "64945d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nomes das colunas no DataFrame:\n",
      "['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added', 'release_year', 'rating', 'duration', 'listed_in', 'description']\n"
     ]
    }
   ],
   "source": [
    "# Nome das colunas\n",
    "print(\"Nomes das colunas no DataFrame:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0343b8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b22a3c4cf241f79fb37e0854ca7b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de linhas do Dataframe: 17509 linhas\n",
      "Quantidade de colunas do Dataframe: 12 colunas\n"
     ]
    }
   ],
   "source": [
    "# Quantidade de linhas e colunas do DataFrame\n",
    "print(f\"Quantidade de linhas do Dataframe: {df.count()} linhas\")\n",
    "print(f\"Quantidade de colunas do Dataframe: {len(df.columns)} colunas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c3707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificação de valores nulos realizada com sucesso.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ca5dd1dcf740f38b031dea1d389e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+--------+----+-------+----------+------------+------+--------+---------+-----------+\n",
      "|show_id|type|title|director|cast|country|date_added|release_year|rating|duration|listed_in|description|\n",
      "+-------+----+-----+--------+----+-------+----------+------------+------+--------+---------+-----------+\n",
      "|      0|   0|    0|    5172|1642|   1657|        10|           0|     4|       3|        0|          0|\n",
      "+-------+----+-----+--------+----+-------+----------+------------+------+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificando os valores nulos de cada coluna\n",
    "try:\n",
    "    nulos_por_coluna = df.select([\n",
    "        sum(when(col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "        for c in df.columns\n",
    "    ])\n",
    "    print(\"Verificação de valores nulos realizada com sucesso.\")\n",
    "    nulos_por_coluna.show()\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao verificar valores nulos: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05474348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos na coluna date_added:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880ec7165f894cd0a305ec849ca84a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       date_added|\n",
      "+-----------------+\n",
      "|December 31, 2017|\n",
      "|       2021-05-11|\n",
      "|       2020-09-20|\n",
      "|    March 1, 2018|\n",
      "|       2020-12-28|\n",
      "|       2020-11-22|\n",
      "|       2020-08-20|\n",
      "|February 15, 2018|\n",
      "|       2021-04-06|\n",
      "|       2021-02-15|\n",
      "|       2020-09-02|\n",
      "|  August 13, 2019|\n",
      "|December 19, 2017|\n",
      "|       2020-09-29|\n",
      "|   March 29, 2019|\n",
      "|       2020-10-12|\n",
      "|       2021-09-09|\n",
      "|       2021-08-12|\n",
      "|       2021-07-01|\n",
      "|       2020-10-11|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Verificando os valores únicos da coluna date_added\n",
    "df_unicos = df.select(\"date_added\").distinct()\n",
    "\n",
    "# Mostra os valores\n",
    "print(\"Valores únicos na coluna date_added:\")\n",
    "df_unicos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5bc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos na coluna release_year:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f78d942cf884747ae596d2b5564d1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|release_year|\n",
      "+------------+\n",
      "|        1987|\n",
      "|        1975|\n",
      "|        1964|\n",
      "|        2013|\n",
      "|        1954|\n",
      "|        1993|\n",
      "|        2009|\n",
      "|        1991|\n",
      "|        1992|\n",
      "|        2003|\n",
      "|        2011|\n",
      "|        2005|\n",
      "|        2018|\n",
      "|        1979|\n",
      "|        2019|\n",
      "|        2004|\n",
      "|        1988|\n",
      "|        1943|\n",
      "|        1997|\n",
      "|        2020|\n",
      "+------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# Verificando os valores únicos da coluna release_year\n",
    "df_unicos = df.select(\"release_year\").distinct()\n",
    "\n",
    "# Mostra os valores\n",
    "print(\"Valores únicos na coluna release_year:\")\n",
    "df_unicos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66989a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos na coluna type:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35dfbf98b27e4eaeafd3679c563bef89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   type|\n",
      "+-------+\n",
      "|TV Show|\n",
      "|  Movie|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificando os valores únicos da coluna type\n",
    "df_unicos = df.select(\"type\").distinct()\n",
    "\n",
    "# Mostra os valores\n",
    "print(\"Valores únicos na coluna type:\")\n",
    "df_unicos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8a24a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos na coluna rating:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e0d1ea3be840acb0a124d5b099b3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|  rating|\n",
      "+--------+\n",
      "|   TV-14|\n",
      "|    TV-Y|\n",
      "|   TV-PG|\n",
      "|      UR|\n",
      "|   TV-Y7|\n",
      "|       G|\n",
      "|   TV-MA|\n",
      "|      NR|\n",
      "|       R|\n",
      "|      PG|\n",
      "|    TV-G|\n",
      "|   PG-13|\n",
      "|TV-Y7-FV|\n",
      "|   NC-17|\n",
      "|    NULL|\n",
      "|  84 min|\n",
      "|  74 min|\n",
      "|  66 min|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificando os valores únicos da coluna rating\n",
    "df_unicos = df.select(\"rating\").distinct()\n",
    "\n",
    "# Mostra os valores\n",
    "print(\"Valores únicos na coluna rating:\")\n",
    "df_unicos.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c007d",
   "metadata": {},
   "source": [
    "Normalizando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a1ad9a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|               title|            director|                cast|             country|       date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
      "|  s6566|  Movie|         Dark Crimes|  Alexandros Avranas|Jim Carrey, Marto...|United Kingdom, P...| October 15, 2019|        2016|     R|   93 min|   Dramas, Thrillers|A detective on a ...|\n",
      "|  s6567|  Movie|         Dark Places|Gilles Paquet-Bre...|Charlize Theron, ...|United States, Un...|    July 26, 2018|        2015|     R|  113 min|Dramas, Internati...|Years after survi...|\n",
      "|  s6568|  Movie|      Darna Mana Hai|        Prawal Raman|Aftab Shivdasani,...|               India|   August 1, 2019|        2003| TV-MA|  116 min|Horror Movies, In...|Stranded in a jun...|\n",
      "|  s6569|TV Show|Darr Sabko Lagta Hai|                NULL|        Bipasha Basu|               India|    March 1, 2018|        2015| TV-MA| 1 Season|International TV ...|In this chilling ...|\n",
      "|  s6570|  Movie|               Darra|       Parveen Kumar|Gurpreet Ghuggi, ...|               India| October 15, 2017|        2016| TV-14|  121 min|Dramas, Internati...|After returning f...|\n",
      "|  s6571|  Movie|Daughters of the ...|          Julie Dash|Cora Lee Day, Alv...|United Kingdom, U...|    June 10, 2017|        1991|    NR|  112 min|Classic Movies, D...|An African Americ...|\n",
      "|  s6572|TV Show|       Day and Night|                NULL|Pan Yueming, Wang...|               China|   March 23, 2018|        2017| TV-MA| 1 Season|Crime TV Shows, I...|A detective assis...|\n",
      "|  s6573|TV Show|Days We Stared at...|                NULL|Sean Huang, Chang...|              Taiwan|   March 31, 2018|        2017| TV-MA|2 Seasons|International TV ...|A model student r...|\n",
      "|  s6574|  Movie|             Dayveon|        Amman Abbasi|Devin Blackmon, D...|       United States| January 11, 2018|        2017| TV-MA|   76 min|Dramas, Independe...|Following the sho...|\n",
      "|  s6575|  Movie|De Film van Dylan...|Dylan Haegens, Ba...|Dylan Haegens, Ni...|         Netherlands|   April 17, 2019|        2018| TV-PG|   81 min|Comedies, Interna...|A YouTuber become...|\n",
      "|  s6576|  Movie|            De Palma|Noah Baumbach, Ja...|      Brian De Palma|       United States|November 21, 2018|        2015|     R|  110 min|       Documentaries|Iconoclastic film...|\n",
      "|  s6577|  Movie|Dead in a Week (O...|         Tom Edmunds|Tom Wilkinson, An...|      United Kingdom|    March 1, 2019|        2018| TV-MA|   90 min|            Comedies|After several fai...|\n",
      "|  s6578|  Movie|Deadline: Sirf 24...|        Tanveer Khan|Irrfan Khan, Konk...|               India|December 31, 2019|        2006| TV-14|   97 min|Independent Movie...|A surgeon’s perfe...|\n",
      "|  s6579|  Movie|     Deadly Scholars|      Danny J. Boyle|Kennedy Lea Slocu...|       United States|February 15, 2019|        2018| TV-14|   86 min|   Dramas, Thrillers|After a series of...|\n",
      "|  s6580|  Movie|                Dean|      Demetri Martin|Demetri Martin, K...|       United States|   March 15, 2020|        2016| PG-13|   94 min|Comedies, Dramas,...|As his father tak...|\n",
      "+-------+-------+--------------------+--------------------+--------------------+--------------------+-----------------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 15 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4845fdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Conversão para pandas realizada com sucesso.\n",
      "- Limpeza inicial da coluna date_added realizada com sucesso.\n",
      "- Conversão para datetime realizada com sucesso.\n",
      "- Formatação da coluna date_added realizada com sucesso.\n",
      "- Conversão da coluna date_added para datetime realizada com sucesso.\n",
      "+-------+-------+--------------------+---------------+--------------------+--------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|               title|       director|                cast|       country|date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+---------------+--------------------+--------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "|  s8755|  Movie|              Wolves|Bart Freundlich|Michael Shannon, ...| United States|2019-03-29|        2016|     R|  109 min|Dramas, Independe...|A promising high ...|\n",
      "|  s8756|TV Show|   Women Behind Bars|           NULL|                NULL| United States|2016-11-01|        2010| TV-14|3 Seasons|Crime TV Shows, D...|This reality seri...|\n",
      "|  s8757|  Movie|           Woodstock|  Barak Goodman|                NULL| United States|2019-08-13|        2019| TV-MA|   97 min|Documentaries, Mu...|For the 50th anni...|\n",
      "|  s8758|  Movie|  World Trade Center|   Oliver Stone|Nicolas Cage, Mic...| United States|2019-11-20|        2006| PG-13|  129 min|Action & Adventur...|Working under tre...|\n",
      "|  s8759|TV Show|World's Busiest C...|           NULL|Anita Rani, Ade A...|United Kingdom|2019-02-01|        2017| TV-PG| 1 Season|British TV Shows,...|From Moscow to Me...|\n",
      "+-------+-------+--------------------+---------------+--------------------+--------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Converte para pandas\n",
    "# Melhora a manipulação de datas com formatos mistos\n",
    "try:\n",
    "\n",
    "    # Converte DataFrame Spark para pandas\n",
    "    df_pandas = df.toPandas()\n",
    "    print(\"- Conversão para pandas realizada com sucesso.\")\n",
    "\n",
    "    # Remove espaços e normaliza valores nulos/vazios\n",
    "    df_pandas['date_added'] = df_pandas['date_added'].astype(str).str.strip()\n",
    "    df_pandas['date_added'] = df_pandas['date_added'].replace(['', 'None', 'nan', 'NaT'], 'noIns')\n",
    "    print(\"- Limpeza inicial da coluna date_added realizada com sucesso.\")\n",
    "\n",
    "    # Converte para datetime de forma inteligente (mixed format)\n",
    "    df_pandas['date_added'] = pd.to_datetime(df_pandas['date_added'], format='mixed', errors='coerce')\n",
    "    print(\"- Conversão para datetime realizada com sucesso.\")\n",
    "\n",
    "    # Converte para string no formato yyyy-MM-dd, substituindo nulos por \"noIns\"\n",
    "    df_pandas['date_added'] = df_pandas['date_added'].dt.strftime('%Y-%m-%d').fillna('noIns')\n",
    "    print(\"- Formatação da coluna date_added realizada com sucesso.\")\n",
    "\n",
    "    # Recria o DataFrame do Spark\n",
    "    df = spark.createDataFrame(df_pandas)\n",
    "    print(\"- Conversão da coluna date_added para datetime realizada com sucesso.\")\n",
    "    df.show(5)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao converter a coluna date_added: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c04ff8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos na coluna date_added após a limpeza:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7daffd845b40b6aed5d30120ecdd94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|date_added|\n",
      "+----------+\n",
      "|2021-05-11|\n",
      "|2020-01-11|\n",
      "|2020-09-20|\n",
      "|2019-11-20|\n",
      "|2020-12-28|\n",
      "+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Verificando os valores únicos da coluna date_added após a limpeza\n",
    "df_unicos = df.select(\"date_added\").distinct()\n",
    "print(\"Valores únicos na coluna date_added após a limpeza:\")\n",
    "df_unicos.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca947679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando os valores nulos da coluna date_added:\n",
      "+-------+-------+-------------------+--------+--------------------+-------------+----------+------------+------+----------+--------------------+--------------------+\n",
      "|show_id|   type|              title|director|                cast|      country|date_added|release_year|rating|  duration|           listed_in|         description|\n",
      "+-------+-------+-------------------+--------+--------------------+-------------+----------+------------+------+----------+--------------------+--------------------+\n",
      "|  s6796|TV Show|            Frasier|    NULL|Kelsey Grammer, J...|United States|     noIns|        2003| TV-PG|11 Seasons|Classic & Cult TV...|Frasier Crane is ...|\n",
      "|  s6807|TV Show|            Friends|    NULL|Jennifer Aniston,...|United States|     noIns|        2003| TV-14|10 Seasons|Classic & Cult TV...|This hit sitcom f...|\n",
      "|  s6902|TV Show|    Gunslinger Girl|    NULL|Yuuka Nanri, Kana...|        Japan|     noIns|        2008| TV-14| 2 Seasons|Anime Series, Cri...|On the surface, t...|\n",
      "|  s7197|TV Show|           Kikoriki|    NULL|       Igor Dmitriev|         NULL|     noIns|        2010|  TV-Y| 2 Seasons|            Kids' TV|A wacky rabbit an...|\n",
      "|  s7255|TV Show|La Familia P. Luche|    NULL|Eugenio Derbez, C...|United States|     noIns|        2012| TV-14| 3 Seasons|International TV ...|This irreverent s...|\n",
      "+-------+-------+-------------------+--------+--------------------+-------------+----------+------------+------+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Verificando os valores nulos de cada coluna novamente\n",
    "print(\"Verificando os valores nulos da coluna 'date_added':\")\n",
    "df.filter(F.col(\"date_added\") == \"noIns\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999312e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Normalização de dados realizada com sucesso.\n",
      "+-------+-------+--------------------+---------------+--------------------+--------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|               title|       director|                cast|       country|date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+---------------+--------------------+--------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "|  s8755|  Movie|              Wolves|Bart Freundlich|Michael Shannon, ...| United States|2019-03-29|        2016|     R|  109 min|Dramas, Independe...|A promising high ...|\n",
      "|  s8756|TV Show|   Women Behind Bars|         notIns|              notIns| United States|2016-11-01|        2010| TV-14|3 Seasons|Crime TV Shows, D...|This reality seri...|\n",
      "|  s8757|  Movie|           Woodstock|  Barak Goodman|              notIns| United States|2019-08-13|        2019| TV-MA|   97 min|Documentaries, Mu...|For the 50th anni...|\n",
      "|  s8758|  Movie|  World Trade Center|   Oliver Stone|Nicolas Cage, Mic...| United States|2019-11-20|        2006| PG-13|  129 min|Action & Adventur...|Working under tre...|\n",
      "|  s8759|TV Show|World's Busiest C...|         notIns|Anita Rani, Ade A...|United Kingdom|2019-02-01|        2017| TV-PG| 1 Season|British TV Shows,...|From Moscow to Me...|\n",
      "+-------+-------+--------------------+---------------+--------------------+--------------+----------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Normalizando dados\n",
    "# Substituindo valores nulos ou vazios por 'notIns'\n",
    "try:\n",
    "    df_clean = df\n",
    "    for c in df.columns:\n",
    "        df_clean = df_clean.withColumn(\n",
    "            c,\n",
    "            F.when(\n",
    "                F.col(c).isNull() | (F.trim(F.col(c)) == \"\"),  # nulo ou vazio\n",
    "                F.lit(\"notIns\")\n",
    "            ).otherwise(F.col(c))\n",
    "        )\n",
    "    print(\"- Normalização de dados realizada com sucesso.\")\n",
    "    df_clean.show(5)\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao normalizar dados: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e4134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificação de valores nulos após a normalização realizada com sucesso.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02d53505b9744d89911833ff761073c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+--------+----+-------+----------+------------+------+--------+---------+-----------+\n",
      "|show_id|type|title|director|cast|country|date_added|release_year|rating|duration|listed_in|description|\n",
      "+-------+----+-----+--------+----+-------+----------+------------+------+--------+---------+-----------+\n",
      "|      0|   0|    0|       0|   0|      0|         0|           0|     0|       0|        0|          0|\n",
      "+-------+----+-----+--------+----+-------+----------+------------+------+--------+---------+-----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44229b9557e2477d8ffb363d9701ab53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+--------+----+-------+----------+------------+------+--------+---------+-----------+\n",
      "|show_id|type|title|director|cast|country|date_added|release_year|rating|duration|listed_in|description|\n",
      "+-------+----+-----+--------+----+-------+----------+------------+------+--------+---------+-----------+\n",
      "|      0|   0|    0|       0|   0|      0|         0|           0|     0|       0|        0|          0|\n",
      "+-------+----+-----+--------+----+-------+----------+------------+------+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificando os valores nulos de cada coluna\n",
    "try:\n",
    "    nulos_por_coluna = df_clean.select([\n",
    "        sum(when(col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "        for c in df_clean.columns\n",
    "    ])\n",
    "    print(\"Verificação de valores nulos após a normalização.\")\n",
    "    nulos_por_coluna.show()\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao verificar valores nulos: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ed5e0a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b51f7d0feb4fda83ddf0e40715de4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames carregados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{catalog_name}.{schema_silver}.{table_silver}\")\n",
    "    print(\"DataFrames carregados com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar DataFrames: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "45cd9dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cd4c4640ae41e5b8fa695b7509f4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, bar_style='success'), Label(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+----------------+--------------------+--------------------+----------+------------+------+--------+--------------------+--------------------+\n",
      "|show_id|   type|               title|        director|                cast|             country|date_added|release_year|rating|duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+----------------+--------------------+--------------------+----------+------------+------+--------+--------------------+--------------------+\n",
      "|  s8754|  Movie|           Withdrawn|   Adrian Murray|Aaron Keogh, Moll...|              Canada|2018-05-01|        2017| TV-MA|  74 min|Dramas, Independe...|Unable to pay bil...|\n",
      "|  s4378|  Movie|Trevor Noah: Son ...|David Paul Meyer|         Trevor Noah|       United States|2018-11-20|        2018| TV-MA|  64 min|     Stand-Up Comedy|\"Daily Show\" host...|\n",
      "|  s4379|  Movie|     The Pixar Story|   Leslie Iwerks|         Stacy Keach|       United States|2018-11-18|        2007|     G|  89 min|       Documentaries|Go behind the sce...|\n",
      "|  s4380|TV Show|        Eternal Love|          notIns|Yang Mi, Mark Cha...|               China|2018-11-17|        2017| TV-14|1 Season|International TV ...|After the deities...|\n",
      "|  s4381|TV Show|             La Doña|          notIns|Aracely Arámbula,...|United States, Me...|2018-11-17|        2016| TV-14|1 Season|Spanish-Language ...|Worlds collide an...|\n",
      "+-------+-------+--------------------+----------------+--------------------+--------------------+----------+------------+------+--------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Carregando os dados da tabela silver para verificação\n",
    "df_silver = spark.read.table(f\"{catalog_name}.{schema_silver}.{table_silver}\")\n",
    "df_silver.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
